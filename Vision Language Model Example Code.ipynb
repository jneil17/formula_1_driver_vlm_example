{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2b420d4-23f0-40c4-bad1-12899a29ecce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üèéÔ∏è Formula 1 Driver Mood Analysis with Vision Language Models\n",
    "\n",
    "Welcome to the fast lane! In this notebook, we'll use cutting-edge AI to analyze the moods of F1 2025 drivers from their official photos.\n",
    "\n",
    "## What We'll Do:\n",
    "\n",
    "* üñºÔ∏è **Download** images of all 20 F1 2025 drivers\n",
    "* ü§ñ **Analyze** their moods using Databricks' Claude Sonnet 4 Vision Language Model\n",
    "* üîç **Search** for drivers by mood using Vector Search (semantic search)\n",
    "* üéØ **Discover** which drivers look confident, happy, or intensely focused\n",
    "\n",
    "Let's get started! üèÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27ca280-ccde-40f7-943d-ebb809abf6a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîß Step 1: Install Required Libraries\n",
    "\n",
    "First, we need to install the necessary Python packages for working with Databricks Vector Search, LangChain, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e8bcb7-fbc3-406f-bda6-a2125e6de0b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U --quiet databricks-sdk==0.49.0 \"databricks-langchain>=0.4.0\" databricks-agents mlflow[databricks] databricks-vectorsearch==0.55 langchain==0.3.25 langchain_core==0.3.59 bs4==0.0.2 markdownify==0.14.1 pydantic==2.10.1\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a6aad1-53ff-40a9-b146-b90496d4cfb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì¶ Step 2: Create Catalog, Schema, and Volume\n",
    "\n",
    "Now we'll create the Unity Catalog objects to store our F1 driver images. Don't worry - if they already exist, these commands won't break anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0087ea-86c4-4d7e-a934-b7f54b51bfe4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configuration Parameters"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration - Update these values for your environment\n",
    "catalog_name = \"formula1\"\n",
    "schema_name = \"default\"\n",
    "volume_name = \"driver_images\"\n",
    "table_name = \"driver_images_table\"\n",
    "\n",
    "# Derived paths\n",
    "volume_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/\"\n",
    "full_table_name = f\"{catalog_name}.{schema_name}.{table_name}\"\n",
    "\n",
    "print(f\"Catalog: {catalog_name}\")\n",
    "print(f\"Schema: {schema_name}\")\n",
    "print(f\"Volume: {volume_name}\")\n",
    "print(f\"Volume Path: {volume_path}\")\n",
    "print(f\"Table: {full_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de179277-fbea-496f-b276-9d755a5c82ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Catalog, Schema, and Volume"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "167a4d88-9c35-4dab-999e-bab35878b10e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Clean the volume if you want to start fresh\n",
    "dbutils.fs.rm(volume_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13fc91e-1b0a-47fb-bdcd-507cd7037da5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üì∏ Step 3: Download F1 2025 Driver Images\n",
    "\n",
    "Time to grab all 20 driver photos from GitHub! We'll compress them to save space while keeping great quality.\n",
    "\n",
    "**Fun fact:** We're downloading images of champions like Max Verstappen, Lewis Hamilton, and rising stars like Kimi Antonelli! üèéÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0445f34d-fbdd-4dd3-8497-3d578491a099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "image_filenames = [\n",
    "    \"Alexander_Albon_23.png\",\n",
    "    \"Carlos_Sainz_55.png\",\n",
    "    \"Charles_Leclerc_16.png\",\n",
    "    \"Esteban_Ocon_31.png\",\n",
    "    \"Fernando_Alonso_14.png\",\n",
    "    \"Gabriel_Bortoleto_5.png\",\n",
    "    \"George_Russell_63.png\",\n",
    "    \"Isack_Hadjar_6.png\",\n",
    "    \"Jack_Doohan_7.png\",\n",
    "    \"Kimi_Antonelli_12.png\",\n",
    "    \"Lance_Stroll_18.png\",\n",
    "    \"Lando_Norris_4.png\",\n",
    "    \"Lewis_Hamilton_44.png\",\n",
    "    \"Liam_Lawson_30.png\",\n",
    "    \"Max_Verstappen_1.png\",\n",
    "    \"Nico_Hulkenberg_27.png\",\n",
    "    \"Oliver_Bearman_87.png\",\n",
    "    \"Oscar_Piastri_81.png\",\n",
    "    \"Pierre_Gasly_10.png\",\n",
    "    \"Yuki_Tsunoda_22.png\"\n",
    "]\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/toUpperCase78/formula1-datasets/be28da6b5a94315dd5fc8c3fc5f240fdccf6f723/F1%202025%20Season%20Drivers/\"\n",
    "\n",
    "for filename in image_filenames:\n",
    "    url = f\"{base_url}{filename}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Load image into PIL\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # Resize to smaller dimensions (adjust as needed)\n",
    "        # This keeps aspect ratio and makes max dimension 800px\n",
    "        max_size = (800, 800)\n",
    "        img.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save as JPEG with compression (quality 85 is good balance)\n",
    "        output_filename = filename.replace('.png', '.jpg')\n",
    "        img.convert('RGB').save(\n",
    "            f\"{volume_path}{output_filename}\", \n",
    "            'JPEG', \n",
    "            quality=85, \n",
    "            optimize=True\n",
    "        )\n",
    "        print(f\"Saved compressed: {output_filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0d68638-5287-4872-9863-70b840bb2e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "# Display images in a grid\n",
    "thumb_files = [f for f in os.listdir(volume_path) if f.endswith('.jpg')]\n",
    "grid_html = \"<table><tr>\"\n",
    "\n",
    "for idx, img_file in enumerate(thumb_files):\n",
    "    img_path = f\"{volume_path}{img_file}\"\n",
    "    if os.path.exists(img_path):\n",
    "        # Read image and convert to base64\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img_data = base64.b64encode(f.read()).decode()\n",
    "        \n",
    "        grid_html += f\"<td><img src='data:image/jpeg;base64,{img_data}' width='120'><br>{img_file.replace('.jpg','')}</td>\"\n",
    "        if (idx + 1) % 5 == 0:\n",
    "            grid_html += \"</tr><tr>\"\n",
    "\n",
    "grid_html += \"</tr></table>\"\n",
    "\n",
    "displayHTML(grid_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5cabf6c-ecc0-4148-b86c-1fd319e913cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ü§ñ Step 4: Analyze Driver Moods with AI\n",
    "\n",
    "Here's where the magic happens! We'll use **Claude Sonnet 4** (a Vision Language Model) to analyze each driver's mood from their photo.\n",
    "\n",
    "The AI will look at facial expressions, body language, and overall vibe to describe how each driver appears. This creates a table with:\n",
    "* üñºÔ∏è Image path\n",
    "* üí¨ AI-generated mood description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2753f9d0-bc32-4a23-9716-68d843ace64a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {full_table_name}\n",
    "TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "SELECT\n",
    "  ai_query(\n",
    "    'databricks-claude-sonnet-4',\n",
    "    'Please describe the mood of the person of the person in the image',\n",
    "    files => files.content\n",
    "  ) AS enriched_caption,\n",
    "  files.path\n",
    "FROM READ_FILES('{volume_path}', format => 'binaryFile') AS files\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a266822-634d-4ad8-9690-495716b62910",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üëÄ Step 5: View the Results\n",
    "\n",
    "Let's see what the AI thinks about our drivers' moods!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b717ea1-b1a0-4ec1-a39d-b1011d7f8768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(full_table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4e59956-2895-4292-b62a-df37ae47d6af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîç Step 6: Set Up Vector Search\n",
    "\n",
    "Now for the cool part! We'll create a **Vector Search** system that lets us search for drivers by mood using natural language.\n",
    "\n",
    "**What's Vector Search?** It converts text (mood descriptions) into mathematical vectors, allowing semantic search. Instead of exact keyword matching, it understands *meaning*!\n",
    "\n",
    "First, let's initialize the Vector Search client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57b78409-06d8-40df-9ae0-8dfabacbc741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient(disable_notice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446bda31-c834-454f-867a-ee094d8278d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create unique names with timestamp\n",
    "timestamp = str(int(time.time()))\n",
    "endpoint_name = f'f1_drivers_endpoint_{timestamp}'\n",
    "index_name = f'{catalog_name}.{schema_name}.f1_drivers_index_{timestamp}'\n",
    "\n",
    "print(f\"Creating new endpoint: {endpoint_name}\")\n",
    "print(f\"Creating new index: {index_name}\")\n",
    "\n",
    "# Create the vector search endpoint\n",
    "try:\n",
    "    endpoint = vsc.create_endpoint(\n",
    "        name=endpoint_name, \n",
    "        endpoint_type='STANDARD'\n",
    "    )\n",
    "    print(f\"‚úÖ Successfully created endpoint: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating endpoint: {e}\")\n",
    "    raise\n",
    "\n",
    "# Wait a moment for endpoint to be ready\n",
    "print(\"Waiting for endpoint to be ready...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Create the vector search index\n",
    "try:\n",
    "    index = vsc.create_delta_sync_index(\n",
    "        endpoint_name=endpoint_name,\n",
    "        index_name=index_name,\n",
    "        source_table_name=full_table_name,\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"path\",\n",
    "        embedding_source_column='enriched_caption',\n",
    "        embedding_model_endpoint_name='databricks-gte-large-en'\n",
    "    )\n",
    "    print(f\"‚úÖ Successfully created index: {index_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating index: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nüéâ Vector search setup complete!\")\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "print(f\"Index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34b82c45-6ec8-43d3-be5d-e59ecaf66823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üèÅ Step 7: Test Semantic Search!\n",
    "\n",
    "Time to put our Vector Search to the test! We'll search for drivers based on their mood descriptions.\n",
    "\n",
    "**How it works:** You describe a mood in natural language, and the AI finds drivers whose photos match that vibe - even if the exact words aren't in the description!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab939fe7-4ec6-42c7-866b-63a960297c7e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Search: Confident Drivers"
    }
   },
   "outputs": [],
   "source": [
    "# Construct the index name dynamically\n",
    "index_name = f\"{catalog_name}.{schema_name}.f1_drivers_index_{timestamp}\"\n",
    "\n",
    "print(f\"Testing vector search with index: {index_name}\")\n",
    "print(\"Searching for: Confident and determined drivers...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test semantic search for confident drivers\n",
    "    results = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        search_score,\n",
    "        REGEXP_EXTRACT(path, r'([^/]+)\\\\.jpg$', 1) as driver_name,\n",
    "        enriched_caption\n",
    "    FROM VECTOR_SEARCH(\n",
    "        index => '{index_name}',\n",
    "        query_text => 'confident and determined professional athlete',\n",
    "        num_results => 5\n",
    "    )\n",
    "    ORDER BY search_score DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"‚úÖ Vector search is working!\")\n",
    "    print(\"üèÜ Top 5 drivers with confident mood:\\n\")\n",
    "    display(results)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Vector search not ready yet: {e}\")\n",
    "    print(\"The index is still building embeddings. This typically takes 5-10 minutes.\")\n",
    "    print(\"\\nüîç Showing text-based search as fallback:\\n\")\n",
    "    \n",
    "    confident_drivers = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        REGEXP_EXTRACT(path, r'([^/]+)\\\\.jpg$', 1) as driver_name,\n",
    "        enriched_caption\n",
    "    FROM {full_table_name}\n",
    "    WHERE LOWER(enriched_caption) LIKE '%confident%'\n",
    "    ORDER BY driver_name\n",
    "    \"\"\")\n",
    "    display(confident_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72bd2de-6382-4472-b349-c0d85a8ffa54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéâ Search for Celebratory Drivers\n",
    "\n",
    "Let's find drivers who look like they're ready to pop champagne on the podium!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3a4ecad-753e-40a3-b0f6-f6990ffd2c8c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Search: Happy Drivers"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    results2 = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        search_score,\n",
    "        REGEXP_EXTRACT(path, r'([^/]+)\\\\.jpg$', 1) as driver_name,\n",
    "        enriched_caption\n",
    "    FROM VECTOR_SEARCH(\n",
    "        index => '{index_name}',\n",
    "        query_text => 'happy celebrating victory triumph',\n",
    "        num_results => 3\n",
    "    )\n",
    "    ORDER BY search_score DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"üéâ Top 3 drivers with celebratory mood:\\n\")\n",
    "    display(results2)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Vector search not ready yet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b5e2667-af57-41cf-ae2f-acad47a2f1bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéØ Search for Focused Drivers\n",
    "\n",
    "Who's got that intense, race-day concentration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f1a00b-7f4b-4dac-930c-2b2db0ee8c8b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Search: Serious Drivers"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    results3 = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        search_score,\n",
    "        REGEXP_EXTRACT(path, r'([^/]+)\\\\.jpg$', 1) as driver_name,\n",
    "        enriched_caption\n",
    "    FROM VECTOR_SEARCH(\n",
    "        index => '{index_name}',\n",
    "        query_text => 'serious focused intense concentration',\n",
    "        num_results => 3\n",
    "    )\n",
    "    ORDER BY search_score DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"üéØ Top 3 drivers with serious/focused mood:\\n\")\n",
    "    display(results3)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Vector search not ready yet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4321e4d7-869b-40b5-9307-503f46ec8332",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üèÜ Bonus: Meet the Champion!\n",
    "\n",
    "Let's take a closer look at Max Verstappen - the reigning world champion! We'll show his photo and what the AI thinks about his mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e6f6695-6773-4d6e-94c8-759fefedc0c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get Max Verstappen's AI-generated mood caption\n",
    "max_caption = spark.sql(f\"\"\"\n",
    "    SELECT enriched_caption\n",
    "    FROM {full_table_name}\n",
    "    WHERE path LIKE '%Max_Verstappen_1%'\n",
    "\"\"\").collect()\n",
    "\n",
    "if max_caption:\n",
    "    print(\"\\nüèéÔ∏è Max Verstappen - 2024 World Champion\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüí¨ AI Mood Analysis:\")\n",
    "    print(f\"{max_caption[0]['enriched_caption']}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\\nüñºÔ∏è Photo:\")\n",
    "\n",
    "# Display the image\n",
    "from IPython.display import Image as IPImage, display as ip_display\n",
    "import os\n",
    "\n",
    "# Read the image file\n",
    "image_path = f\"{volume_path}Max_Verstappen_1.jpg\"\n",
    "if os.path.exists(image_path):\n",
    "    ip_display(IPImage(filename=image_path, width=400))\n",
    "else:\n",
    "    print(f\"Image not found at: {image_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Vision Language Model Example Code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
